{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom category_encoders import MEstimateEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_validate, GridSearchCV\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import Lasso, Ridge\nfrom sklearn.linear_model import ElasticNet, BayesianRidge\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Data","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\", index_col='Id')\ntest_df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\", index_col='Id')\nsubmisson = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/sample_submission.csv\")","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"markdown","source":"## Missing Values","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"markdown","source":"### Check Missing Values","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"colnul_train = train_df.isnull().sum()[train_df.isnull().sum() > 0].sort_values(ascending=False) / 1460\ncolnul_test = test_df.isnull().sum()[test_df.isnull().sum() > 0].sort_values(ascending=False) / 1459\n\nfig, axes = plt.subplots(1, 2, figsize=(20,10))\nsns.barplot(x=colnul_train, y=colnul_train.index, ax=axes[0])\nsns.barplot(x=colnul_test, y=colnul_test.index, ax=axes[1])\naxes[0].set_title('Missing values in training data')\naxes[1].set_title('Missing values in testing data')\naxes[0].set_xlabel('Nan Values')\naxes[1].set_xlabel('Nan Values')","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fill Missing values","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"markdown","source":"Mode :\n\t\n    FireplaceQu\n\t\n     MasVnrType\n\t\n     Electrical\n     \n     Alley\n\n     Fence\n\n\nNone :\n\t\n    GarageType\n\t\n     GarageFinish\n\t\n     GarageQual\n\t\n     GarageCond\n\nYearBuilt :\n\t\n    GarageYrBlt\n\nNoBsmt :\n\t\n    BsmtExposure\n\t\n     BsmtFinType1\n\t\n     BsmtFinType2\n\t\n     BsmtCond\n\t\n     BsmtQual\n\n0 :\n\n    MasVnrArea\n\n     GarageYrBlt\n\n     GarageCars\n\n     GarageArea\n\n     BsmtFinSF1\n\n     BsmtFinSF2\n\n     BsmtUnfSF\n\n     TotalBsmtSF\n\n     BsmtFullBath\n\n     BsmtHalfBath","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"#Categorical\nfor df in [train_df, test_df]:\n    for i in ['FireplaceQu', 'MasVnrType', 'Electrical', 'Alley', 'Fence']:\n        mode = train_df[i].mode()[0]\n        df[i] = df[i].fillna(mode)\n\n    for i in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n        df[i] = df[i].fillna('None')\n\n    for i in ['BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtCond', 'BsmtQual']:\n        df[i] = df[i].fillna('NoBsmt')\n\n    df['MiscFeature'] = df['MiscFeature'].fillna('NoMisc')\n    df['PoolQC'] = df['PoolQC'].fillna('TA')\n\n    df.drop(\"Utilities\", axis=1, inplace=True)\n\n#Numerical\nfor df in [train_df, test_df]:\n    df.loc[(df['LotFrontage'].isna()) & (df['Street'] == 'Grvl'), 'LotFrontage'] = train_df.groupby('Street')['LotFrontage'].mean()['Grvl']\n    df.loc[(df['LotFrontage'].isna()) & (df['Street'] == 'Pave'), 'LotFrontage'] = train_df.groupby('Street')['LotFrontage'].mean()['Pave']\n\n    for i in ['GarageYrBlt', 'MasVnrArea', 'GarageCars', 'GarageArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']:\n        df[i] = df[i].fillna(0)\n\nfor i in  [\"Functional\",\"KitchenQual\", \"Exterior1st\", \"Exterior2nd\", \"MSZoning\", \"SaleType\"] :\n    mode = train_df[i].mode()[0]\n    test_df[i] = test_df[i].fillna(mode)","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Missing value in train_df : {}'.format(train_df.isna().sum().sum()))\nprint('Missing value in test_df : {}'.format(test_df.isna().sum().sum()))","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoding Categorical Data\n\n**Categorical Variable** :\n\n     Nominal -> no intrinsic ordering\n     Ordinal -> clear ordering","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"categorical = train_df.loc[:, train_df.dtypes == 'object'].nunique() # get number of unique values\nnumerical = train_df.loc[:, train_df.dtypes != 'object'].columns","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get Unique values for each Categorical Variable","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"cat_var_unique = {i : sorted(train_df[i].unique()) for i in categorical.index}\ndf_cat_var_unqiue = pd.DataFrame.from_dict(cat_var_unique, orient='index').sort_values([x for x in range(25)])","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ordinal Encoding","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"#Group each ordinal variable based on thei unique values.\n\nord_var1 = [\"ExterCond\", \"HeatingQC\"]\nord_var1_cat = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n\nord_var2 = [\"ExterQual\", \"KitchenQual\"]\nord_var2_cat = [\"Fa\", \"TA\", \"Gd\", \"Ex\"]\n\nord_var3 = [\"FireplaceQu\", \"GarageQual\", \"GarageCond\"]\nord_var3_cat = [\"None\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n\nord_var4 = [\"BsmtQual\"]\nord_var4_cat = [\"NoBsmt\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n\nord_var5 = [\"BsmtCond\"]\nord_var5_cat = [\"NoBsmt\", \"Po\", \"Fa\", \"TA\", \"Gd\"]\n\nord_var6 = [\"BsmtExposure\"]\nord_var6_cat = [\"NoBsmt\", \"No\", \"Mn\", \"Av\", \"Gd\"]\n\nord_var7 = [\"BsmtFinType1\", \"BsmtFinType2\"]\nord_var7_cat = [\"NoBsmt\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"]\n\n# Put all in one array for easier iteration\nord_var = [ord_var1, ord_var2, ord_var3, ord_var4, ord_var5, ord_var6, ord_var7]\nord_var_cat = [ord_var1_cat, ord_var2_cat, ord_var3_cat, ord_var4_cat, ord_var5_cat, ord_var6_cat, ord_var7_cat]\nord_all = ord_var1 + ord_var2 + ord_var3 + ord_var4 + ord_var5 + ord_var6 + ord_var7 ","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(ord_var)):\n    encoder = OrdinalEncoder(categories=[ord_var_cat[i]])\n    for var in ord_var[i]:\n        train_df[var] = encoder.fit_transform(train_df[[var]])\n        test_df[var] = encoder.fit_transform(test_df[[var]])","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One-Hot Encoding","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"categorical = categorical.drop(ord_all)\nonehot_var = categorical[categorical < 6].index # only variable with a unique values less than 6\n\ntrain_df = pd.get_dummies(train_df, prefix=onehot_var, columns=onehot_var)\ntest_df = pd.get_dummies(test_df, prefix=onehot_var, columns=onehot_var)","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get encoded variables name that do not yet exist in the test_df\nadd_var = [var for var in train_df.columns if var not in test_df.columns]\n\nfor var in add_var:\n    if var != 'SalePrice':\n        test_df[var] = 0","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reorder test_df column so it is the same order as the train_df\ntest_df = test_df[train_df.columns.drop('SalePrice')]","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Target Encoding\n\nThe problem with One-Hot Encoding is that the more unique values in a variable, the more new columns will be created. In that case, it can lead to high memory consumption and increase the computational cost. Therefore, we will use target encoding for variables with 6 or more unique values.\n\nHere we eill use M-Estimate Encoder, this is a simplified version of target encoder, which goes under names like m-probability estimate or additive smoothing with known incidence rates. In comparison to target encoder, m-probability estimate has only one tunable parameter (m), while target encoder has two tunable parameters (min_samples_leaf and smoothing).","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"categorical = categorical.drop(onehot_var)\nx_train = train_df.drop('SalePrice', axis=1)\ny_train = train_df['SalePrice']","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Mest = MEstimateEncoder(cols=train_df[categorical.index.append(pd.Index(['MoSold']))]) ## Add MoSold variable to the encoder\nx_train = Mest.fit_transform(x_train, y_train)\ntest_df = Mest.transform(test_df)\ntrain_df = pd.concat([x_train, y_train], axis=1)","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"sns.set_theme(rc={'figure.figsize':(24,20)})\nsns.heatmap(train_df[numerical].corr(), annot=True, fmt='.2f')","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train_df[numerical].corr()[['SalePrice']]\nplt.figure(figsize=(20, 15))\nsns.barplot(x='SalePrice', y=train.index, data=train)\nplt.axvline(x=0.5, color='r')","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating New Variables\n\nNow we will create some new variables based on variables that have a high correlation in the data above to avoid collinearity. We will also create new features that might be useful.","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"for df in [train_df, test_df]:\n    df['GarAreaPerCar'] = (df['GarageArea'] / df['GarageCars']).fillna(0)\n    df['GrLivAreaPerRoom'] = df['GrLivArea'] / df['TotRmsAbvGrd']\n    df[\"TotalHouseSF\"] = df[\"TotalBsmtSF\"] + df[\"1stFlrSF\"] + df[\"2ndFlrSF\"]\n    df[\"TotalFullBath\"] = df[\"FullBath\"] + df[\"BsmtFullBath\"]\n    df[\"TotalHalfBath\"] = df[\"HalfBath\"] + df[\"BsmtHalfBath\"]\n    df[\"InitHouseAge\"] = df[\"YrSold\"] - df[\"YearBuilt\"]\n    df[\"RemodHouseAge\"] = df[\"InitHouseAge\"] - (df[\"YrSold\"] - df[\"YearRemodAdd\"])\n    df[\"IsRemod\"] = (df[\"YearRemodAdd\"] - df[\"YearBuilt\"]).apply(lambda x: 1 if x > 0 else 0)\n    df[\"GarageAge\"] = (df[\"YrSold\"] - df[\"GarageYrBlt\"]).apply(lambda x: 0 if x > 2000 else x)\n    df[\"IsGarage\"] = df[\"GarageYrBlt\"].apply(lambda x: 1 if x > 0 else 0)\n    df['TotalPorchSF'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch']\n    df[\"AvgQualCond\"] = (df[\"OverallQual\"] + df[\"OverallCond\"]) / 2","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deleting Variables","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"for df in [train_df, test_df]:\n    df = df.drop([\"GarageArea\", \"GarageCars\", \"GrLivArea\", \n            \"TotRmsAbvGrd\", \"TotalBsmtSF\", \"1stFlrSF\", \n            \"2ndFlrSF\", \"FullBath\", \"BsmtFullBath\", \"HalfBath\", \n            \"BsmtHalfBath\", \"YrSold\", \"YearBuilt\", \"YearRemodAdd\",\n            \"GarageYrBlt\", \"OpenPorchSF\", \"EnclosedPorch\", \"3SsnPorch\",\n            \"ScreenPorch\", \"OverallQual\", \"OverallCond\"], \n            axis=1)","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"markdown","source":"## Splitting Data","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"X_train = train_df.drop(['SalePrice'], axis=1)\ny_train = train_df['SalePrice']\nX_test = test_df","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scaling Data","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\ny_train_log = np.log10(y_train)","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Selecting Best Model","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"model = {\n    'XGB' : XGBRegressor(),\n    'LGBM' : LGBMRegressor(),\n    'Lasso' : Lasso(),\n    'Ridge' : Ridge(),\n    'Elastic Net' : ElasticNet(),\n    'Bayesian Ridge' : BayesianRidge(),\n    'SVR' : SVR(),\n    'Gradient Boosting' : GradientBoostingRegressor()\n}\n\nresult = pd.DataFrame(columns=['Model', 'Avg_RMSE'])\n\nfor name, mod in model.items():\n    model = mod\n    crossvad = cross_validate(model, X_train_scaled, y_train_log, cv=10, scoring=(['neg_root_mean_squared_error']))\n    result = result.append({'Model' : name, 'Avg_RMSE' : np.abs(crossvad['test_neg_root_mean_squared_error']).mean()}, ignore_index=True)\n\nresult = result.sort_values('Avg_RMSE', ascending=True)\nresult.reset_index(drop=True)","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will choose three best model from cross validation test above, which is Gradient Boosting, LGBM, and XGB.","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"markdown","source":"## Hyperparameter Tuning","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"markdown","source":"### Gradient Boosting","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"gb = GradientBoostingRegressor(random_state=0)\nparams = {\n    'loss' : ('squared_error', 'absolute_error'),\n    'learning_rate' : (1.0, 0.1, 0.01),\n    'n_estimators' : (50, 100, 200)\n}\n\nmod1 = GridSearchCV(gb, params, cv=10)\nmod1.fit(X_train_scaled, y_train_log)\nprint('Best hyperparameter : ', mod1.best_params_)","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = mod1.predict(X_train_scaled)\nprint(f'Train RMSE : {mean_squared_error(y_train_log, y_pred, squared=False)}')","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LGBM","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"lgbm = LGBMRegressor(random_state=0)\nparams = {\n    'num_leaves' : (11, 31, 51),\n    'learning_rate' : (0.5, 0.1, 0.05),\n    'n_estimators' : (50, 100, 200)\n}\n\nmod2 = GridSearchCV(lgbm, params, cv=10)\nmod2.fit(X_train_scaled, y_train_log)\nprint('Best hyperparameter : ', mod2.best_params_)","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = mod2.predict(X_train_scaled)\nprint(f'Train RMSE : {mean_squared_error(y_train_log, y_pred, squared=False)}')","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGB","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"xgb = XGBRegressor(random_state=0)\nparams = {\n    'max_depth' : (3, 6, 9),\n    'learning_rate' : (0.3, 0.1, 0.05),\n    'n_estimators' : (50, 100, 200)\n}\n\nmod3 = GridSearchCV(xgb, params, cv=10)\nmod3.fit(X_train_scaled, y_train_log)\nprint('Best hyperparameter : ', mod3.best_params_)","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = mod3.predict(X_train_scaled)\nprint(f'Train RMSE : {mean_squared_error(y_train_log, y_pred, squared=False)}')","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stacking 3 Models","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"def mod_predict(x):\n        return (3 * mod1.predict(x) + 5 * mod2.predict(x) + 2 * mod3.predict(x)) / 10\n\ny_pred_stack = mod_predict(X_train_scaled)\nprint(f'Train RMSE with stacking : {mean_squared_error(y_train_log, y_pred_stack, squared=False)}')","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"datalore":{"type":"MD","hide_input_from_viewers":false,"hide_output_from_viewers":false}}},{"cell_type":"code","source":"y_pred = mod_predict(X_test_scaled)\ny_pred_inv = 10 ** y_pred","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submisson['SalePrice'] = y_pred_inv\nsubmisson.to_csv('submission.csv', index=False)","metadata":{"datalore":{"type":"CODE","hide_input_from_viewers":false,"hide_output_from_viewers":false}},"execution_count":null,"outputs":[]}]}